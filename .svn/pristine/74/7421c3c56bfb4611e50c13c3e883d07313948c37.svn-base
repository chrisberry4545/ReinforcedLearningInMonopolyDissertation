/*
 * To change this template, choose Tools | Templates
 * and open the template in the editor.
 */
package monopoly;

import Controller.ActionManager;
import Model.Game;
import Model.Players.FirstTDPlayer;
import Model.Players.NeuralNetwork.AbstractEvaluator;
import Model.Players.NeuralNetwork.Evaluator;
import Model.Players.NeuralNetwork.Generalizer;
import Model.Players.NeuralNetwork.Critic;

/**
 *
 * @author chris
 */
public class Main {
    
    private static final String FILE_TO_LOAD = "first_try";
    private static final String FILE_NAME_TO_SAVE_TO = FILE_TO_LOAD;
    /**
     * @param args the command line arguments
     */
    public static void main(String[] args) {
        int gamesToRun = 100000;
        double lambda = 0.5;
        AbstractEvaluator evaluator = 
                new AbstractEvaluator(lambda, FirstTDPlayer.NUM_INPUT_NODES, 
                FirstTDPlayer.NUM_HIDDEN_NODES, 
                FirstTDPlayer.NUM_OUTPUT_NODES);
        //evaluator.loadNet(FILE_TO_LOAD);
        
        //Network needs to be reset so nodes created first know about their
        //output nodes created later.
        evaluator.restartNetwork();
        Generalizer generalizer = new Generalizer(evaluator);
        Critic critic = new Critic(generalizer);
        ActionManager am = ActionManager.getInstance();
        for (int i = 0; i < gamesToRun; i++) {
            System.out.println("On run :" + i);   
            //startNewGame vars: critic, showGraphics, numHumanPlayers, numRandomAIs, numTDAIs.
            am.startNewGame(critic, false, 0, 0, 2);
        }
        System.out.println("Out of " + gamesToRun + ", " +
                am.getGamesOver250Rounds() + " of them ran over 250 rounds");
        evaluator.saveNet(FILE_NAME_TO_SAVE_TO);
    }
}
