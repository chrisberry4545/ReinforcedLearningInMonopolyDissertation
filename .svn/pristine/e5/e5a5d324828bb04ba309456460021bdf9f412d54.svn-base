/*
 * To change this template, choose Tools | Templates
 * and open the template in the editor.
 */
package monopoly;

import Controller.ActionManager;
import Model.GameStats;
import Model.Players.NeuralNetwork.AbstractEvaluator;
import Model.Players.NeuralNetwork.CriticPackage.Critic;
import Model.Players.NeuralNetwork.Generalizer;
import Model.Players.TDInputGenerator;
import java.util.ArrayList;
import java.util.List;
import java.util.Random;

/**
 *
 * @author Chris
 */
public class StandardRun {

    public static void standardRun(TDInputGenerator tdInputGen,
            double lambda, String fileToSaveTo, String file_To_Load,
            String second_File_To_Load, int starting_Runs,
            int runsBeforeSave, int totalNumberOfRuns,
            int numberOfNetworks, int numHumanPlayers, int numRandomPlayers,
            int numFullTDPlayers, int numSimpleTDAIs, int numDBGenRandomAIs,
            boolean differentRunTypes, boolean displayGraphics, boolean newNetwork,
            boolean fixedWeights, boolean blockLearning, boolean feedResultsToNet) {
 
        int amountOfSaves = totalNumberOfRuns / runsBeforeSave;
        boolean useExploratoryMoves;
        if (blockLearning) {
            useExploratoryMoves = false;
        } else {
            useExploratoryMoves = true;
        }
        int numInputNodes = tdInputGen.getNumInputNodes();
        int numHiddenNodes = tdInputGen.getNumHiddenNodes();
        int numOutputNodes = tdInputGen.getNumOutputNodes();
        AbstractEvaluator evaluator;
        if (newNetwork) {
            if (!fixedWeights) {
                evaluator = new AbstractEvaluator(lambda, numInputNodes, numHiddenNodes, numOutputNodes);
            } else {
                evaluator = new AbstractEvaluator(lambda, numInputNodes, numHiddenNodes, numOutputNodes);
            }
            evaluator.restartNetwork();
            String fileName = fileToSaveTo;
            evaluator.saveNet(fileName);
            System.out.println("Saving new network as: " + fileName);
        } else {
            System.out.println("Loading: " + file_To_Load);
            evaluator = new AbstractEvaluator(file_To_Load);
        }
        System.out.println("Learning blocked.. " + blockLearning);
        System.out.println("Using exploratory moves.. " + useExploratoryMoves);
        System.out.println("Number of networks.. " + numberOfNetworks);
        AbstractEvaluator evaluator2;
        Generalizer generalizer2;
        Critic critic2 = null;
        List<Critic> criticList = new ArrayList();
        List<TDInputGenerator> inputGenList = new ArrayList();
        if (numberOfNetworks == 2) {
            if (!newNetwork) {
                System.out.println("Loading Network 2: " + second_File_To_Load);
                evaluator2 = new AbstractEvaluator(second_File_To_Load);
                generalizer2 = new Generalizer(evaluator2);
                critic2 = new Critic(generalizer2, numOutputNodes);
                critic2.setBlockLearning(true);
            }
        }
        GameStats.setUpGameStats(numHumanPlayers + numRandomPlayers + numFullTDPlayers + numSimpleTDAIs + numDBGenRandomAIs);
        Generalizer generalizer = new Generalizer(evaluator);
        Critic critic = new Critic(generalizer, numOutputNodes);
        critic.setBlockLearning(blockLearning);
        ActionManager am = ActionManager.getInstance();
        criticList.add(critic);
        criticList.add(critic2);
        inputGenList.add(tdInputGen);
        inputGenList.add(tdInputGen);
        if (!feedResultsToNet) {
            for (int runs = 0; runs < amountOfSaves; runs++) {
                for (int i = 0; i < runsBeforeSave; i++) {
                    int runType = ActionManager.RUNTYPE_NORMALGAME;
                    if (differentRunTypes) {
                        Random random = new Random();
                        runType = random.nextInt(ActionManager.RUNTYPE_RANDOMSTART);
                    }
                    if (numberOfNetworks < 2) {
                        am.startNewGame(critic, tdInputGen, displayGraphics, numHumanPlayers, numRandomPlayers, numFullTDPlayers, numSimpleTDAIs, numDBGenRandomAIs, useExploratoryMoves, runType);
                    } else {
                        am.startNewGame(criticList, inputGenList, displayGraphics, numHumanPlayers, numRandomPlayers, numFullTDPlayers, numSimpleTDAIs, numDBGenRandomAIs, useExploratoryMoves, runType);
                    }
                }
                System.out.println("Saving the file (Save number: " + runs + ").");
                int startingRuns;
                if (newNetwork) {
                    startingRuns = 0;
                } else {
                    startingRuns = starting_Runs;
                }
                int totalRuns = (runs * runsBeforeSave) + runsBeforeSave + startingRuns;
                String fileNameToSave = fileToSaveTo + totalRuns;
                evaluator.saveNet(fileNameToSave);
            }
            int finalRuns = totalNumberOfRuns + starting_Runs;
            String title = fileToSaveTo + finalRuns;
            GameStats.writeToCSV(title + "GameStats.csv", GameStats.getCSVString());
            GameStats.writeToCSV(title + "OfferedDeals.csv", GameStats.getOfferedDealCSVString());
            GameStats.writeToCSV(title + "AcceptedDeals.csv", GameStats.getCompletedDealCSVString());
            GameStats.printWinValues();
        } else {
            System.out.println("Feeding results to network...");
            if (!newNetwork) {
                System.err.println("Error.. Not a new network.. Exiting..");
                System.exit(0);
            }
            int numRums = FeedResultsToNetwork.feedResultsToNetwork(critic);
            String fileNameToSaveTo = fileToSaveTo + numRums;
            evaluator.saveNet(fileNameToSaveTo);
            System.out.println("Saved Network: " + fileNameToSaveTo);
        }
    }
    
}
